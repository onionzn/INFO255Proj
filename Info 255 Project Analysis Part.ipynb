{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04093367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import nan\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "21b91997",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_image = pd.read_csv('./data/merged_image_match_facial_recognition.csv')\n",
    "matched = merged_image[merged_image['image_match']>0.4]\n",
    "merged_df = pd.read_csv('./data/merged.csv')\n",
    "merged_df['bd'] = merged_df['bd'].astype(str).str[:4] #just taking the year\n",
    "#looking at yelp and tinder merged dataframe after cross matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eeeb507",
   "metadata": {},
   "source": [
    "Wanted to look into l-diversity based on our merged table, which is the table we are working with, which is a combination of 2 public tables to see how secure the table is after combining all the information based on what we know. I am looking at user_name as it is one of the more specific quasi-identifiers that are used and since names are a very helpful clue for connecting social media platforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e7555427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Kevin L.      240\n",
       "Chris M.      221\n",
       "Michael U.    168\n",
       "Chris L.      136\n",
       "John D.       135\n",
       "             ... \n",
       "Patrick B.      1\n",
       "Shannon Z.      1\n",
       "Shannon B.      1\n",
       "Shannon D.      1\n",
       "Elena C.        1\n",
       "Name: user_name, Length: 2159, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[\"user_name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9b4146eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lorena        1\n",
       "Kevan         1\n",
       "Brooks        1\n",
       "Arun          1\n",
       "Buck          1\n",
       "             ..\n",
       "Maximilian    1\n",
       "Kegan         1\n",
       "Cherry        1\n",
       "Mady          1\n",
       "Rin           1\n",
       "Name: name, Length: 69, dtype: int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = merged_df['name'].value_counts()\n",
    "single = name[name==1]\n",
    "single"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e435e35c",
   "metadata": {},
   "source": [
    "As you can see here, there are a lot of Kevins, Chris', Michaels, etc. but there are still a lot of very specific names like Elena C. and Shannon D.. With these, this means that the equivalence classes for names leads to a k-anonymity score of only 1 for the whole table since that is the only number that satisfies all of the equivalence classes.This makes it very easy for anyone to point out who these people are in the dataset and know the urls to their Yelp profile, which can then reveal a lot of information about their lifestyle and the places they frequent.\n",
    "\n",
    "I also looked at different combinations of equivalence classes, and the minimum k was still 1 for many. This means that there are no other people that could mask their identitity, and if someone looks up the name Rin and Kegan, they will be identified and and known within the dataset.\n",
    "\n",
    "So let's say for now that the user_first name is the sensitive attribute even though the url to their Yelp page is what is going to give away the most information. Since those will all be unique values, I wanted to explore the names since there are 69 different unique names we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "97a1ea26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qID = {\"bd\", \"gender\", \"user_first_name\"}\n",
    "equivalence_classes = merged_df[qID].drop_duplicates()\n",
    "k_list = merged_df.groupby([\"bd\", \"gender\", \"user_first_name\"], dropna = False).size().reset_index(name='k')\n",
    "ec_sorted = k_list.sort_values([\"bd\", \"gender\", \"user_first_name\"], ascending = [True, True, True])\n",
    "k = min(ec_sorted[\"k\"])\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "d5c79f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 1.077942907891244\n"
     ]
    }
   ],
   "source": [
    "bd_l = []\n",
    "for i in merged_df[\"bd\"].drop_duplicates():\n",
    "    val = merged_df[merged_df[\"bd\"] == str(i)] #get all the rows with that year\n",
    "    val_per_type = val[{\"bd\", \"user_first_name\"}].value_counts()\n",
    "    bd_l.append(len(val_per_type))\n",
    "    p = val_per_type/14888\n",
    "    bd_entropy = 10**((-sum(val_per_type * np.log10(p)))/14888)\n",
    "bd_distinct = min(bd_l) #wanted to see what the min was with more than 1 quasi-identifierdiversity \n",
    "print(bd_distinct, bd_entropy) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadb108e",
   "metadata": {},
   "source": [
    "quasi-identifier birth year (bd) satisfy 3 Distinct l-diversity and is 1.0779 entropy diverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "03db3293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 1.2391340474474293\n"
     ]
    }
   ],
   "source": [
    "gender_l = []\n",
    "for i in merged_df[\"gender\"].drop_duplicates(): #go through each ec\n",
    "    val = merged_df[merged_df[\"gender\"] == str(i)] #get all the rows with that year\n",
    "    val_per_type = val[{\"gender\", \"user_first_name\"}].value_counts()\n",
    "    gender_l.append(len(val_per_type))\n",
    "    p = val_per_type/14888\n",
    "    gender_entropy = 10**((-sum(val_per_type * np.log10(p)))/14888)\n",
    "gender_distinct = min(gender_l) #wanted to see what the min was with more than 1 quasi-identifierdiversity \n",
    "print(gender_distinct, gender_entropy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ee6908",
   "metadata": {},
   "source": [
    "quasi-identifier gender satisfy 38 Distinct l-diversity and is 1.2391 entropy diverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "1bae67c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1.0017162141298677\n"
     ]
    }
   ],
   "source": [
    "gender_l = []\n",
    "mm = merged_df[[\"bd\",\"gender\"]].drop_duplicates()\n",
    "for i in np.arange(len(mm)): #go through each ec\n",
    "    gen = mm.iloc[i, :][1]\n",
    "    b = mm.iloc[i, :][0]\n",
    "    val = merged_df[(merged_df[\"gender\"] == gen) & (merged_df[\"bd\"] == b)] #get all the rows\n",
    "    val_per_type = val[{\"gender\", \"bd\",\"user_first_name\"}].value_counts()\n",
    "    gender_l.append(len(val_per_type))\n",
    "    p = val_per_type/14888\n",
    "    gender_entropy = 10**((-sum(val_per_type * np.log10(p)))/14888)\n",
    "gender_distinct = min(gender_l) #wanted to see what the min was with more than 1 quasi-identifierdiversity \n",
    "print(gender_distinct, gender_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6011ec41",
   "metadata": {},
   "source": [
    "quasi-identifier gender satisfy 1 Distinct l-diversity and is 1.0017 entropy diverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "a5d36c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1.0011983482384246\n"
     ]
    }
   ],
   "source": [
    "#trying it out with birthday year and city\n",
    "gender_l = []\n",
    "mmm = merged_df[[\"bd\",\"city\"]].drop_duplicates()\n",
    "mmm['city'].fillna('Unknown')\n",
    "for i in np.arange(len(mmm)): #go through each ec\n",
    "    city = mmm.iloc[i, :][1]\n",
    "    b = mmm.iloc[i, :][0]\n",
    "    merged_df['city'] = merged_df['city'].fillna('Unknown')\n",
    "    val = merged_df[(merged_df[\"city\"] == city) & (merged_df[\"bd\"] == b)] #get all the rows\n",
    "    val_per_type = val[{\"city\", \"bd\",\"user_first_name\"}].value_counts()\n",
    "    gender_l.append(len(val_per_type))\n",
    "    p = val_per_type/14888\n",
    "    gender_entropy = 10**((-sum(val_per_type * np.log10(p)))/14888)\n",
    "gender_distinct = min(gender_l) #wanted to see what the min was with more than 1 quasi-identifierdiversity \n",
    "print(gender_distinct, gender_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351ec2ca",
   "metadata": {},
   "source": [
    "Satisfies 1 Distinct l-diversity and 1.0012 entropy diverse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08592a9c",
   "metadata": {},
   "source": [
    "Seeing the numbers here, having more than 2 quasi-identifiers leads to an l-diversity distinct score of 1, which isn't too great and also a low entropy diverse score. This means that the user_name can be hurtful for those with more unique names as people can more accurately identify them on both Atinder and Yelp and thus lead a potential stalker to inofrmation that can reveal information on lifestyle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36516e42",
   "metadata": {},
   "source": [
    "Now looking into l-diveristy and t-closeness, we wanted to explore delta-presence to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "aa5a640b",
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_identities = pd.read_csv('./data/reviews_with_first_name.csv')\n",
    "tinder_identities = pd.read_csv('./data/tinder_users_no_dup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "2b1a4a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>city</th>\n",
       "      <th>school</th>\n",
       "      <th>user_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>not displayed</td>\n",
       "      <td>Mountain View</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ryan M.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>not displayed</td>\n",
       "      <td>Mountain View</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ryan H.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>not displayed</td>\n",
       "      <td>Mountain View</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ryan G.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>not displayed</td>\n",
       "      <td>Berkeley</td>\n",
       "      <td>University of California, Berkeley</td>\n",
       "      <td>Daniel D.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>not displayed</td>\n",
       "      <td>Berkeley</td>\n",
       "      <td>University of California, Berkeley</td>\n",
       "      <td>Daniel X.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>University of California, Berkeley</td>\n",
       "      <td>Matthew T.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>University of California, Berkeley</td>\n",
       "      <td>Matthew M.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>not displayed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>San Francisco State University</td>\n",
       "      <td>Levi S.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            gender           city                              school  \\\n",
       "190  not displayed  Mountain View                                 NaN   \n",
       "203  not displayed  Mountain View                                 NaN   \n",
       "212  not displayed  Mountain View                                 NaN   \n",
       "236  not displayed       Berkeley  University of California, Berkeley   \n",
       "242  not displayed       Berkeley  University of California, Berkeley   \n",
       "335           male            NaN  University of California, Berkeley   \n",
       "350           male            NaN  University of California, Berkeley   \n",
       "376  not displayed            NaN      San Francisco State University   \n",
       "\n",
       "      user_name  \n",
       "190     Ryan M.  \n",
       "203     Ryan H.  \n",
       "212     Ryan G.  \n",
       "236   Daniel D.  \n",
       "242   Daniel X.  \n",
       "335  Matthew T.  \n",
       "350  Matthew M.  \n",
       "376     Levi S.  "
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quasi_identifiers = {\"gender\", \"city\", \"school\"}\n",
    "matched = matched.rename(columns={\"4\": \"gender\", \"5\": \"city\", \"6\": \"distance\", \"7\": \"company\", \"8\": \"job_title\", \"9\": \"school\"})\n",
    "identities = matched[{\"gender\", \"city\", \"school\", \"user_name\"}]\n",
    "identities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5a95e9",
   "metadata": {},
   "source": [
    "Looking at this, we can see that just looking at the 8 different identities that we were able to successfully match based on multiple factors such as city and facial expression. We can see that if we just take into accoun thte quasi-identifiers that only Levi is the only person that doesn't have the same exact quasi-identifiers as another person. However, this is a small list anyways, but considering this, there are a lot of overlap for the other individuals, which can help mask them more in terms of l-diversity.\n",
    "\n",
    "The number isn't too big though, so adding more quasi-identifiers that reveal more information can still be good for an attacker as they only have to elimate 2 out of 3 entries for the Ryans in Mountain View and 1 out of 2 for the Daniels and Matthews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "3a282dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "iden = matched[{\"gender\", \"city\", \"school\"}].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "8fdca2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pqID = merged_df[{ \"gender\", \"city\", \"school\"}]\n",
    "iqID = iden.iloc[0, :]\n",
    "left, right = pqID.align(iqID, axis=1, copy=False)\n",
    "check = left == right\n",
    "check[(check[\"city\"] == True) & (check[\"gender\"] == True) & (check[\"school\"] == True)]\n",
    "prob_of_identifying = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "b49dd253",
   "metadata": {},
   "outputs": [],
   "source": [
    "pqID = merged_df[{ \"gender\", \"city\", \"school\"}]\n",
    "iqID = iden.iloc[1, :]\n",
    "left, right = pqID.align(iqID, axis=1, copy=False)\n",
    "check = left == right\n",
    "check[(check[\"city\"] == True) & (check[\"gender\"] == True) & (check[\"school\"] == True)]\n",
    "prob_of_identifying = 1/532"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "21e47ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pqID = merged_df[{ \"gender\", \"city\", \"school\"}]\n",
    "iqID = iden.iloc[2, :]\n",
    "left, right = pqID.align(iqID, axis=1, copy=False)\n",
    "check = left == right\n",
    "check[(check[\"city\"] == True) & (check[\"gender\"] == True) & (check[\"school\"] == True)]\n",
    "prob_of_identifying = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6508b08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pqID = merged_df[{ \"gender\", \"city\", \"school\"}]\n",
    "iqID = iden.iloc[3, :]\n",
    "left, right = pqID.align(iqID, axis=1, copy=False)\n",
    "check = left == right\n",
    "check[(check[\"city\"] == True) & (check[\"gender\"] == True) & (check[\"school\"] == True)]\n",
    "prob_of_identifying = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9609ea3b",
   "metadata": {},
   "source": [
    "We can see here that we were unable to locate most of these in our overall merged dataset after combining the Tinder and Yelp data except for the Berkeley entries for the city and school."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc16053",
   "metadata": {},
   "source": [
    "Extra just to see what the numbers looked like in terms of the difference between positive reviews and if there that could arise from privacy concerns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "794abac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_in_texts(words, texts):\n",
    "    indicator_array = []\n",
    "    for x in texts:\n",
    "        boo = []\n",
    "        for i in words:\n",
    "            if i in x:\n",
    "                boo.append(1)\n",
    "            else:\n",
    "                boo.append(0)        \n",
    "        indicator_array.append(boo)     \n",
    "    return np.array(indicator_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "426a7791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([710, 870, 206,  22,  19,  40,  39,  17,  49])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = ['amazing', 'delicious', 'worth', 'satisfied', 'awful', 'negative','concern', 'angry', 'rude']\n",
    "ba = words_in_texts(l, merged_df['text'])\n",
    "words = pd.DataFrame({\"words\": l, \"count\": sum(ba)})\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe410695",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
